{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature-engineering-chapter2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTXdtJjdSj_V",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 2: Fancy Tricks with Simple Numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxheza0zSuxi",
        "colab_type": "text"
      },
      "source": [
        "- Numeric data also need feature engineering\n",
        "- Sanity check for numeric data: \n",
        "    - Whether the magnitude matters. Such as the number of daily visits to a website.\n",
        "    - Scale of the features. What are the largest and the smalles values? Do they span several orders of magnitude?\n",
        "    - The distribution of numeric features. The training process of a linear regression model assumes that prediction errors are distributed like a Gaussian. If the target distribution has multi-hump, skew to right or left. Then we need to transform the target vector, by power transform (log transform).\n",
        "    - Composing multiple features into more complex features. Complex features may themselves be the output of statistical models (model stacking) \n",
        "- Need scaling: k-means clustering, k-nearest neighbors radial basis function (RBF) and anything using euclidean distance\n",
        "- No need scaling: space partitioning trees, decision trees, gradient boosted machines, random forests\n",
        "- Feature selection can reduce the computational expense\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMxat472Wxa2",
        "colab_type": "text"
      },
      "source": [
        "## Scalars, Vectors, and Spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1s5qVEhW3Jd",
        "colab_type": "text"
      },
      "source": [
        "- A single numeric feature is also known as a scalar. An\n",
        "ordered list of scalars is known as a vector. Vectors sit within a vector space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g82G1hN-X1uv",
        "colab_type": "text"
      },
      "source": [
        "## Dealing with Counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA9E8-xRYBFs",
        "colab_type": "text"
      },
      "source": [
        "### Binarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUv5YQZWYSpt",
        "colab_type": "text"
      },
      "source": [
        "Transforming the target or column into binary representation, 0 or 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKJzWELcokMj",
        "colab_type": "text"
      },
      "source": [
        "### Quantization or Binning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILAlkSxRo1V6",
        "colab_type": "text"
      },
      "source": [
        "- Raw counts that span several orders of magnitude are problematic for many models.\n",
        "- A large count in one element of the data vecotr would outweigh the similarity in all other elements, which could throw off the entire similarity measurement. One solution is group the counts into bins, and get rid of the actual count values. It maps continuous number into discrete one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xpx8sWyqvH0",
        "colab_type": "text"
      },
      "source": [
        "__Fixed-width binning__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4CPLUwCqx59",
        "colab_type": "text"
      },
      "source": [
        "- Each bin contains a specific numeric range. They can be linearly scaled or exponentially scaled. Or we can make customed defined ranges which correspond to stages of life.\n",
        "- When the numbers span multiple magnitudes, it may be better to group by powers of 10 (or powers of any constant)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTj7UiELtm-v",
        "colab_type": "code",
        "outputId": "cf68ca32-8c8b-44af-ccf5-b1bb6b27e6fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# generate 20 random integers uniformly between 0 and 99\n",
        "small_counts = np.random.randint(0, 100, 20)\n",
        "print(small_counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1 59 14 59  3 72 35 52 48 43  4  8 31 11 99 54 60 23 11 50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV51nAOLubpf",
        "colab_type": "code",
        "outputId": "e7c49df2-807a-4305-8972-3d5885fda0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# map to evenly spaced bins 0-9 by division\n",
        "np.floor_divide(small_counts, 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 5, 1, 5, 0, 7, 3, 5, 4, 4, 0, 0, 3, 1, 9, 5, 6, 2, 1, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8x99W3BuxeJ",
        "colab_type": "code",
        "outputId": "c1eaa3b4-af9b-4f7b-aaea-6819d061eb0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "# an array of counts that span several magnitudes\n",
        "large_counts = [296, 8286, 64011, 80, 3, 725, 867, 2215, 7689, 11495, \n",
        "                91897, 44, 28, 7971, 926, 122, 22222]\n",
        "\n",
        "# map to exponential-width bins via the log function\n",
        "np.floor(np.log10(large_counts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 3., 4., 1., 0., 2., 2., 3., 3., 4., 4., 1., 1., 3., 2., 2., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXzAsD4svHwB",
        "colab_type": "text"
      },
      "source": [
        "__Quantile Binnning__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McPfaIAmxtaZ",
        "colab_type": "text"
      },
      "source": [
        "- Problem: if there are large gaps in the counts then there will be many empty bins with no data. \n",
        "- Can be solved by adaptively positioning the bins based on the distribution of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVB7mgE1y0Kv",
        "colab_type": "code",
        "outputId": "da5edd61-db85-4400-d699-4207602994e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# map the counts to quartiles\n",
        "pd.qcut(large_counts, 4, labels=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 0, 0, 1, 1, 2, 2, 3, 3, 0, 0, 2, 1, 0, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M1Tio09y-9n",
        "colab_type": "code",
        "outputId": "883dbd83-1faa-4d77-f743-d7a282715694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "# compute the quantiles themselves\n",
        "large_counts_series = pd.Series(large_counts)\n",
        "large_counts_series.quantile([0.25, 0.5, 0.75])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25     122.0\n",
              "0.50     926.0\n",
              "0.75    8286.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STKODzbPbLyV",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wdesKvyzfXz",
        "colab_type": "text"
      },
      "source": [
        "## Log Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3XLb3JozjfU",
        "colab_type": "text"
      },
      "source": [
        "- The log function is the inverse of the exponential function. \n",
        "- The log function compresses the range of large numbers and expands the range of small numbers. The larger x is, the slower log(x) increments.\n",
        "- The log transform is a powerful tool for dealing with positive numbers with heavy-tailed distribution. (A heavy-tailed distribution places more probability mass in the tail range than a gaussian distribution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-Xt53Ev2SBz",
        "colab_type": "text"
      },
      "source": [
        "### Log Transform in Action"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN0i58JE2bOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # adding new column that contains the log-transformed data\n",
        "# dataset['log_column'] = np.log10(dataset['column'] + 1)\n",
        "\n",
        "# # train linear regression models\n",
        "# scores_orig = cross_val_score(LinearRegression(), datataset['column'],\n",
        "#                               dataset['target'], cv=10, scoring='r2')\n",
        "# scores_log = cross_val_score(LinearRegression(), dataset['column'],\n",
        "#                              dataset['target'], cv=10, scoring='r2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl9iXowq4ZNO",
        "colab_type": "text"
      },
      "source": [
        "Why is the log transform has its effect? the log transform reshaped the x-axis, pulling the articles with lage outliers in the target value further out toward the right hand side of the axis. The model try to fit the smaller value harder. This how it works that way, without log transform, small different in input has large different in the output. The best one is small changes in input, will have smaller changes in output, it also aplies for large changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcssRbNR7HQp",
        "colab_type": "text"
      },
      "source": [
        "__The Importance of Data Visualization__\n",
        "\n",
        "It can shows us that several model can not catch the relationship between the feature and target. When building models, it is a good idea to visually inspect the relationships\n",
        "between input and output, and between different input features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALh01h048NJb",
        "colab_type": "text"
      },
      "source": [
        "### Power Transforms: Generalization of the Log Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYgDkh-u8d19",
        "colab_type": "text"
      },
      "source": [
        "- The log transform is an example of power transform. In statistical terms, it is called variance-stabilizing transformation.\n",
        "- Poisson distribution: a heavy-tailed distribution with a variance that is equal to its mean, hence, the larger its center of mass, the larger its variance, and the heavier the tail.\n",
        "- Power transforms change the distribution of the variable so\n",
        "that the variance is no longer dependent on the mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daTj9HbpHl9q",
        "colab_type": "text"
      },
      "source": [
        "The Box-Cox transform:\n",
        "\n",
        " $$ \\hat{x} =   \\left\\{\n",
        "\\begin{array}{ll}\n",
        "     \\frac{x^\\lambda - 1}{\\lambda} & if\\;\\lambda \\neq 0   \\\\\n",
        "      ln(x) & if\\;\\lambda = 0 \\\\\n",
        "\\end{array} \n",
        "\\right.  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpRwouDbIkUx",
        "colab_type": "text"
      },
      "source": [
        "- lambda = 0: log transform\n",
        "- lambda = 0.5: a scaled and shifted version of the square root transform.\n",
        "- Setting lambda to be less than 1 compresses the higher values, and setting lambda higher than 1 has the opposite effect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojo8BkAaJgV9",
        "colab_type": "text"
      },
      "source": [
        "- Only works when the data is positive. For non positive data, one could shift the values by adding a fixed constant.\n",
        "- When applying box-cox transformation or power transformaion, we have determine the value for lambda. It can be done via maximum likelihood or bayesian method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GE8uBNAKQKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from scipy import stats\n",
        "\n",
        "# # check the minimum value in the data, because box-cox only works\n",
        "# # for positive data\n",
        "\n",
        "# # setting the input parameter lambda to 0 gives us the log transform\n",
        "# x_log = stats.boxcox(data['column'], lmbda=0)\n",
        "# # by default the scipy implementation of box-cox transform\n",
        "# # finds the lambda parameter than will make the output the closest to\n",
        "# # a normal distribution\n",
        "# x_bc, bc_params = stats.boxcox(data['column'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02koQyOrMHU3",
        "colab_type": "text"
      },
      "source": [
        "A probability plot or probplot is an easy way to visually compare an empirical distribution of data against a theoretical distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYjv0tq8MU3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prob1 = stats.probplot(data['column'], dist=stats.norm, ax=ax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68As6nmWNNvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNAbCHZ2NWyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.random.normal(loc=0, scale=1.5, size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDFgK6AtPb96",
        "colab_type": "code",
        "outputId": "ee9087fe-ec0d-48cd-d84c-27b16d76e26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.hist(x, bins=50);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-saus9SNPgVP",
        "colab_type": "code",
        "outputId": "bdc7c475-5419-4c6f-afca-21c209df0673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from scipy.stats import probplot, norm\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "prob1 = probplot(x, dist=norm, plot=ax)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VHXaxvHvQ0AhoCJgAwWsKwHB\ngqjYBXsvrLJgXUCCAopdXOuiYENF6fbEFVFsrx0VK1KlBnQtBAULoKiIrpTn/eOcgUkyk0xCZiaT\n3J/r4iJz5pyZJxHnzq8ec3dERERqpbsAERGpGhQIIiICKBBERCSkQBAREUCBICIiIQWCiIgACgSp\nAczsZjPLq+C1F5jZh6U8/5qZnR/rXDNbZWa7VOR9y1njJDPrkez3kepPgSBVkpktMrM/wg/VH8zs\nMTNrkO66inP349398TjPNXD3rwDC+v9d0fepjJ+HmbU0Mzez2hWtQ6o3BYJUZSe7ewNgX6A9cEPx\nEyxQU/4dl/nzENkUNeV/JMlg7r4EeA1oAxu6SAaZ2UfAamAXM2tqZi+Z2U9m9oWZ9Sz2MnXNbJyZ\n/WZmM82sXeQJM7vWzL4Mnysws9OLXWtm9qCZ/WJmC82sU9QTcbtrwt/GdzOzXkA34OrwN/yXzewq\nM3uu2PkPmNn95f15FHuNWmZ2g5kVmtmPZvaEmW0VPv1++PfKsI6DynovqVkUCFLlmdlOwAnAp1GH\nzwV6AVsAhcDTwLdAU+As4HYzOyrq/FOB8UAj4CngBTOrEz73JXAosBVwC5BnZjtEXXtAeE4T4CZg\ngpk1SrR+dx8N5AN3ht1IJwN5wHFm1jD8HmsD5wBPlPV6cX4eEReEf44EdgEaAA+Gzx0W/t0wrGNy\not+D1AwKBKnKXjCzlcCHwHvA7VHPPebu8919LbA9cDBwjbv/6e6zgLHAeVHnz3D3Z919DXAvUBc4\nEMDdx7v7Undf7+7jgP8CHaKu/RG4z93XhM9/Bpy4Kd+Yu39H8Bt7l/DQccByd59RymWl/TwiugH3\nuvtX7r4KuA44R+MGkgj9I5Gq7DR3nxjnuW+ivm4K/OTuv0UdKyToZy9xvruvN7NIawIzOw8YALQM\nT2lA0BqIWOJFd4EsjFy7iR4HcoExQHfgyTLOL+3nEdGUoL6IQoL/z7eraJFSc6iFIJkq+gN6KdDI\nzLaIOtYcWBL1eKfIF+Eg9I7AUjNrQfCBfCnQ2N0bAvMAi7q2mZlFP24evmdF6414AWhrZm2Akwi6\nlTbVUqBF1OPmwFrghzg1iGygQJCM5+7fAB8Dd5hZXTNrC/yToJ8+Yj8zOyPsOrkM+B/wCVCf4INy\nGYCZXUjJwdptgX5mVsfMugCtgFfLWeYPBH360XX/CTxLMKYx1d0Xl/M1Y/kPcLmZ7RxOS70dGBd2\nrS0D1hevQyRCgSDVRVeCLp+lwPPATcW6V14EzgZ+JhiQPiMcEygA7gEmE3xo7wV8VOy1pwC7A8uB\nQcBZ7r6inPU9DOSY2UozeyHq+OPhe5bVXZSoR8LXeh/4GvgT6Avg7qsJ6v8orOPASnpPqSZMN8gR\nSR8zaw4sBLZ391/TXY/UbGohiKRJOJYxAHhaYSBVgWYZiaSBmdUn6KIqJJhyKpJ26jISERFAXUYi\nIhLKqC6jJk2aeMuWLdNdhohIRpkxY8Zyd9+mrPMyKhBatmzJ9OnT012GiEhGMbPCss9Sl5GIiIQU\nCCIiAigQREQkpEAQERFAgSAiIiEFgoiIAAoEEREJKRBERKqy5cuhf3/45Zekv5UCQUSkKnKH/Hxo\n1QqGD4f330/6WyoQRESqmkWL4IQToHt32HVXmDkTTj456W+rQBARqSrWroV774XWreHDD+GBB+Cj\nj2CvvVLy9goEEZGqYPZsOOgguOIKOPJImD8f+vYl/+ksWraEWrWgZcugFylZFAgiIun0xx9w7bWw\n336weDE8/TS8/DI0b05+PvTqBYWFwZBCYWHwOFmhoEAQEUmXd94JuoOGDIHzz4cFC+Dss8EMgIED\nYfXqopesXh0cTwYFgohIqv30E1x0EXTqFDx++214+GFo1KjIaYsXx7483vFNpUAQEUkV96BLqFUr\neOKJoKto7lw46qiYpzdvHvtl4h3fVAoEEZFUWLw4mDratSu0aAEzZsAdd0C9enEvGTQIsrOLHsvO\nDo4ngwJBRCSZ1q0Lpo/m5MC778LQoTB5MrRrV+al3brB6NFBfpgFf48eHRxPhoy6haaISEaZOxd6\n9oQpU+C442DEiGDuaDl065a8AChOLQQRkcr2559www2w777w5ZfBPNFXXyX/o5YpW1NQEWlvIZhZ\nFjAdWOLuJ6W7HhGRTfHWDe+xy5Be7Lr2c56tfz5+2z10+UfjDWsKItNII2sKIHUtgLKkPRCA/sAC\nYMt0FyIiUmE//8wXZ1zN0ZPG8hU7czRvMvH3o8m+Av7aovQ1BVUlENLaZWRmOwInAmPTWYeISEXk\n50PLFk4Xe5Yft8mh5aRHuZOraMM8JnI0sPFDP9VrCioi3WMI9wFXA+vjnWBmvcxsuplNX7ZsWeoq\nExEpJj+fDWMATZrAvy78lvsXn8Z4uvDtuh3owFSu4U7+oOhc0cWLU7+moCLSFghmdhLwo7vPKO08\ndx/t7u3dvf0222yToupERAKREDCDc88N+v7x9Zy94iFmrcnhaN7iSu6iA1P5lH1jvkbz5qlfU1AR\n6RxDOBg4xcxOAOoCW5pZnrt3T2NNIiIbFB8Idocc5jOGnnRkMm9yNL0ZydfsEvc1Ih/6kXGCSPdR\nJCSqyvgBgLl7umvAzI4ArixrllH79u19+vTpqSlKRGqs/Pzgg7uwcOOxzfgf13M713EHv7IlA7iX\nJzkXsCLXNm4MDRpUrQ99M5vh7u3LOq8qzDISEakyircKAA7mQ8bQk1YsJI9uXM5QllOyCzs7G+6/\nP/0BUFHpHlQGwN0naQ2CiFQF0dNDt+QXhpPLhxxKPf7gWF7nXPI2hEGdOkGLIBXbSqSCWggiIqH8\n/I3dRKfxPA9yKdvzPfcwgBu5ldXUxywYS2jRomp0B1UmBYKICBu7inZgKQ9yKWfwPLNox6m8yAyC\n7vfqGALRqkSXkYhIOuXnwwXnrefc1SNZQCuO5zWuYTD7M40ZtCc7G/LyYNGi6hsGoBaCiNRg+fnQ\nvz80WbGQd+jJoXzI2xzFxYziS3bbcF6mjw0kSi0EEalx8vODlcYXdv+LPituZTbtaM18LuQROjOx\nSBi0aFEzwgDUQhCRGiLSGlixInh8EB8zhp60poD/cA6XcR8/sl2Ra6raSuJkUwtBRKq1SGuge/cg\nDLbgV4ZxKR9yCFvwGyfyf/yD/5QIg6ysmtNVFKFAEJFqq0+fYP+hSKvgZF6igBz6MJxh9KU183mV\nE0tcl50Njz9es8IAFAgiUg3l5wfbR4wYEawZ2I7veYYuvMSp/EQjDmIyl3E/q9iixLWNG9e8lkGE\nAkFEMlqkS8hs45/u3eH33wGcfzKWBbTiZF7megaxHzOYygElXqdx42Bq6fLlNTMMQIPKIpLB8vPh\n/PNh3bqSz+3O54ymF0fwHpM4nF6M5r/sUeK8xo0ze/+hyqQWgohkpPz8YHygeBjU4S+uZxBzaEs7\nZtODMRzFOyXCQC2CktRCEJGMUXzqaHEdmMIYetKWuTxDF/rxAD+wfZFzcnNh+PAUFJuB1EIQkYwQ\n6R6KFQYN+I376M9kDqIRP3EKL3I2zygMykmBICJVWvQ6glhjBSfwCvNpTV+GMZw+5FDAy5xS5JxI\n95DCoHTqMhKRKqlPn2DaaDzb8gP3cRldeZr55HAIHzKZjhue12Bx+amFICJVRp8+UKtWMHU0fhg4\nF/AoC2jFGUzgRm5hHz7dEAa5ucHaAw0Wl59aCCJSJbRuDQUFpZ+zK18wkt505m0+4BB6MZqFtAKC\nhWgjRyoENoVaCCKSNpEVxWalh0Ft1nA1Q5jLXuzPNC5mJIfzHgtpRYMGwfjAb78pDDaVWggikhad\nO8Pbb5d93n5MZyw92JvZTOB0+jKMpTQDNGuosqmFICIpl0gYZPM79zCAKRzAtvzI6UzgTCawlGYb\nWgUKg8qlQBCRlEokDI7hDebRhgEMZQw9yaGAFzh9w/RRdQ8lhwJBRJKuT5+NG8+VFgZNWMaTdOcN\njuNP6nIo73NJrZH8I7ehZg6lgMYQRCSpEhsrcLqTx1AuZ0t+5RZu5Pk9r2fWgs1TUaKE1EIQkaTJ\nzy87DHbmK97gWJ7kPD5nD/bhU37IvUVhkAZqIYhI0gwcGP+5LNZyGfdxKzeyltr04SEOfqI388/V\n76npop+8iCRNYWHs4/swkykcwN1cxVscTQ4FHJzXh24Kg7TST19EkqJZs5LH6rGaIVzNVDrQlKWc\nxXhO4wVOyd1Rg8VVgAJBRCpN9GyipUuLPteJicxlL67mLh7lQnIo4I0GZ5GXZ1pPUEVoDEFENllp\nM4kasYJ7GcD5PMHn7M7hTOJ9Dsc9tTVK2dRCEJEKi7QIYoeB05WnWMie/IOn+DcDacsc3udwGjdO\ndaWSCLUQRKRCStudtAWLGEEux/M6U+hAD8Yyj72AIEDuvz+FhUrC0tZCMLOdzOxdMysws/lm1j9d\ntYhIYvLzoXbt+LuT1mIdlzGU+bTmUD6gH/fTkY83hEFWFjz5pFYbV1XpbCGsBa5w95lmtgUww8ze\ncvcydkQXkXTIzw9uYxlPW2Yzhp50YBqvcAK5jOAbmm94vmFD+PnnFBQqFZa2FoK7f+fuM8OvfwMW\nADEmqolIupUWBnX5g9u5jhnsRwsKOYf/cBL/VyQMOnVSGGSCKjGGYGYtgX2AKemtRESKK22s4Eje\nYRQXsztf8AgXciV38zONAKhbF8aOVfdQJkl7IJhZA+A54DJ3/zXG872AXgDNmzcv/rSIJNHWW8PK\nlTGO8xN3cRX/5BG+YFeO4m3e5SgAmjaFJUtSXKhUirROOzWzOgRhkO/uE2Kd4+6j3b29u7ffZptt\nUlugSA0VmU5aMgycvzOOBbTifB5nMNewF3M3hEGnTgqDTJa2FoKZGfAwsMDd701XHSJSVLwuop1Y\nzHD6cBKvMI32HMsbzGbvDc/rdpaZL51dRgcD5wJzzWxWeOx6d381jTWJ1GixwqAW6+jDcG7nemqx\nnsu5l2H0ZR21qVcPVq9OT61S+dIWCO7+IWDpen8R2SjeLKLWzGMsPTiQKbzOsfRmJIW0BFAYVEPl\nGkMws63NrG2yihGR1IsVBpvzJ7dxA5+yD7vyJd3I43he2xAGOTkKg+qozEAws0lmtqWZNQJmAmPM\nTH3+ItVA584lw+Aw3mM27biBQTzFP2jFAp6iG5EGfW4uzJ+f+lol+RJpIWwVTgc9A3jC3Q8AOie3\nLBFJplib0m3FSkbRi/c4gjqs4Rje4AIeZwVNgOD8vDwNHFdniYwh1DazHYC/A6XcEE9EMkHJtQXO\nmTzHMPqyLT9yF1dyMzezmvobztDagpohkRbCrcAbwJfuPs3MdgH+m9yyRKSytW5dcm1BU5bwPKfz\nLF34jh3owFSu5i6FQQ1VZgvB3ccD46MefwWcmcyiRKRyWbH5fMZ6ejOSwVxLbdZyFXcylMtZV+wj\noVMnmDgxhYVKWiUyqLyHmb1tZvPCx23N7IbklyYilWGzzYo+bkUBH3Aow7mEKRxAG+ZxN1eVCIO8\nPIVBTZNIl9EY4DpgDYC7zwHOSWZRIlI5NtsM1qwJv+Z/3MTNzGJv9mQh5/E4x/AmX7NLkWsig8fa\nlK7mSWRQOdvdp1rRNufaJNUjIpUk+n/ZjnzEGHqSwwLy6MblDGU5JfcG0/YTNVsigbDczHYFHMDM\nzgK+S2pVIrJJImGwJb8wmGvJZSSLaMHxvMrrHF/ifA0cCyTWZXQJMArY08yWAJcBuUmtSkQqJD9/\nYxicygsUkEMvRnMvl9OGeTHDIDdXYSCBRGYZfQV0NrP6QK3w7mYiUoX06QMjRgRf78BShtGXM5nA\nbNpyGi8wnf1LXKPuISmuzEAwsxuLPQbA3W9NUk0iUg6RhWbGenoyhiFcw+b8j2u5g3u4grXUKXFN\np04KAykpkS6j36P+rAOOh3CHKxFJm+ib2PyNhUziCEbRm5nsS1vmMIRr44aBppNKLIl0Gd0T/djM\n7iZYuSwiaRKZTlqHv7iGIdzAv/md+lzIIzzGBcTbWd49pWVKhqnI/RCygR0ruxARSUxk0PhAJjOG\nnrRhPk9zNv25nx/ZLu51CgMpSyIrleea2Zzwz3zgM+C+5JcmItEiM4ga8BsP0JePOJit+IWTeJmu\nPK0wkE2WSAvhpKiv1wI/uLsWpomkUOQmNifxMsPpQzOW8CCXMpBBrGKLuNdpfYGUR9xACG+IA1B8\nmumWZoa7/5S8skQkonVrWFHwPePox98Zz1za0IXxTOHAuNfUqQN//ZXCIqVaKK2FMINgdXKs0SmH\nYhugiEilCgaOnYt4hLu5knr8wUD+zV1cxRo2i3udZhFJRcUNBHffOZWFiEggOxv++AN247+MphdH\nMon3OIxejOZz/hb3uoYN4eefU1ioVDuJrEPAzLY2sw5mdljkT7ILE6lpsrODQeM1f6zhWu5gLnux\nD5/Sk9EcybulhkFensJANl0iK5V7AP0JpprOAg4EJgNHJbc0keovMlgcsT9TGUNP2jGH8ZxFPx7g\ne3Yo9TU0g0gqSyIthP7A/kChux8J7AOsLP0SESlL69Ybw6A+qxjKZXzCgTRmBafyAn9nfJlhkJeX\ngkKlxkgkEP509z8BzGxzd18IpbRdRaRUkfUEBQXB4+N5lfm0ph8PMIJccijgJU4t83V0ExupbIms\nQ/jWzBoCLwBvmdnPQGFyyxKpnpo1g6VLg6+34Ufupz9deZoCWnEIHzKZjmW+hmYRSbIkspfR6eGX\nN5vZu8BWwOtJrUqkGtp4BzPnfB7nHq6gAau4iZsZzLX8xeZxr9W6AkmFuF1GZvaqmXU3swaRY+7+\nnru/5O76pymSoGbNNobBLnzJWxzNY1zIAlqxN7O4lZtKDYO8PIWBpEZpYwijgBOBr83sGTM73czi\nr4YRkSIi21MvXQpZrOUq7mQebdifafRmBIfxPgtpFfPaOnWC2UPuGieQ1CltYdqLwItmlg2cDJwH\njDCz14Cn3P2tFNUoknEi21MD7MsMxtKDfZjFBE6nL8NYSrO412oaqaRLmbOM3H21u48LxxKOAfZG\nYwgiJURaBGZBGGTzO3dzBVPpwHb8wBk8x5lMiBsGTZsqDCS9ElmYth3wd+AcYAfgGeCC5JYlklms\n2I5fR/Mmo7iYnVnESC7mWgbzCw3jXq8gkKqgtN1OewJdCdYcPAdc5e4fp6owkUwRHQaNWc5QLudc\n8ljI3ziU9/mQQ+Neq+2ppSoprcvoIOAOYCd375eMMDCz48zsMzP7wsyurezXF0mmzp2LTiXtzpMs\nZE/OZhy38i/2ZlapYZCXpzCQqqW0QeWLkvnGZpYFPAQcDXwLTDOzl9y9IJnvK1IZsrJg/frg65Z8\nzUh6cyxvMpkD6cFYCmgd91otLJOqqiL3VK4sHYAv3P0rADN7GjgVUCBIlRZpFWSxlv7cz63cyHpq\ncSnDGEEu68mKeV2tWrBuXQoLFSmnhLa/TpJmwDdRj78NjxVhZr3MbLqZTV+2bFnKihMpLjKLCGBv\nPuUTDuQeruRtOpFDAQ9xadwwyM1VGEjVl8gtNGNK1S003X00MBqgffv2moshKRe9RXU9VnMTt3AF\n97CcJnThGZ7lLGLdWFA3rJFMk+gtNJsDP4dfNwQWA5t6R7UlwE5Rj3cMj4lUGZG7lwF0YiKjuJhd\n+Yqx/JOruIuVbB3zOu1EKpkobpeRu+/s7rsAE4GT3b2JuzcGTgLerIT3ngbsbmY7h1tinAO8VAmv\nK7LJIncv++MPaMQKHuUCJnI068jiCN6lJ2MVBlLtJDKGcKC7vxp54O6vQQJ79JbB3dcClwJvAAuA\nZ9x9/qa+rsimiNyrIGgVOF15igW0ohv5DOJ62jGb9zgi5rWR/YcUBpKpEplltNTMbgAi92bqBiyt\njDcPg+bVMk8USYHoBWbNKWQEuZzAa0xlfzozkbm0jXttbi4MH56CIkWSKJFA6ArcBDxPMKbwfnhM\nJONtvTWsjLohbC3W0Zdh/JsbAOjPfTxYyuwh0LYTUn0kcoOcn4D+Zlbf3X9PQU0iKVF8/6G9mMNY\netCBabzCCfRhOItpEfd6zSKS6qbMMQQz62hmBQT9/JhZOzNT41gyVvR6AoC6/MEgrmcG+9GSRXTl\nKU7i/0oNA3eFgVQ/iQwqDwWOBVYAuPts4LBkFiWSLFlZMGLExsdH8C5zaMv13EEe3WnFAp6mK7HW\nFUAwVqAuIqmuElqp7O7fFDukNZeSccw27j/UkJ8ZQw/e5SgMpxMTuYhH+YnGMa/NywuCQAPHUp0l\nMqj8jZl1BNzM6gD9CbuPRDJF9K6kXRjPA/SjCcsZzDXcyo38QXbM6+rVg9WrU1amSFol0kLoDVxC\nsM/QEoI7pl2SzKJEKkv0eMGOfMNLnMIznM237Mj+TOM6BscMg8iaAoWB1CSlthDCLarPdXcttZGM\n07kzvP12MJW0D8O5neupxXoGcA8P0I91Mf75az2B1GSlBoK7rzOzfxAMLItkjNatoaAAWjOPMfTk\nID7hDY6hNyNZFGcbLg0WS02XyBjCh2b2IDAO2LAOwd1nJq0qkU1gBpvzJ7cyiGsYwq9sSXeeJJ9u\naFdSkfgSCYS9w79vjTrmwFGVX45IxUS6hwAO5X1G04s9+YwnOJcB3MsKmsS8Tl1EIhslslL5yFQU\nIlIR0UGwFSsZwjVczGi+YmeO4Q3e4pi41yoMRIoqMxDMbDvgdqCpux9vZjnAQe7+cNKrEynFZpvB\nmjXB16czgQe5lO34gbu5gpu4hdXUj3utxgtESkpk2uljBFtUNw0ffw5clqyCRBKRlRWEQVOWMIHT\nmcCZfM/2dGAqV3G3wkCkAhIJhCbu/gywHjbcx0ArlSVtzMDXr6c3Iyggh+N4nau4kw5MZSb7lXqt\nwkAkvkQC4Xcza0wwkIyZHQj8ktSqRGKI3LymFQW8z2GMoA/T2J82zONuroq5riAiJ0dhIFKWRGYZ\nDSC4teWuZvYRsA1wVlKrEokSucn9ZvyPGxnMQAbxG1twPo/xBOcRbyM60NYTIuWRyCyjmWZ2OPA3\ngv/zPnP3NUmvTISNN7DpyEeMoSc5LOApunIZ97GMbeNel5MD83VDVpFyiRsIZnZGnKf2MDPcfUKS\nahLZsNJ4S37hIa6jDyMopDnH8yqvc3zc67TITKTiSmshnBz+vS3QEXgnfHwk8DGgQJBK16wZLA3v\n2H0KLzKcPmzP9wzlMv7FbfxOg7jXqlUgsmniDiq7+4XufiFQB8hx9zPd/UygdXhMpNJEdiVduhS2\n5zvGcxYvchoraMxBTGYAQ0sNg9xchYHIpkpkUHknd/8u6vEPQPMk1SM1UGScwFhPD8ZyJ1dTlz+5\njtu5mytZW8bvH5o9JFI5Epl2+raZvWFmF5jZBcArwMTkliXVXefOQYvALAiDPfiMdzmS0VzMp+zD\nXsxlMNeVGgZNmyoMRCpTIrOMLjWz09l4H+XR7v58csuS6ix6y4k6/MXV3Mm/uI3VZPNPxvIIF1Ha\nVFINHIskR6ktBDPLMrN33f15d788/KMwkHLLz4fatYMWQSQMDuATZrAf/+ZfvMBptGIBj/BP4oWB\nWXBvY4WBSHKUGgjuvg5Yb2ZbpageqUYiA8VmwcKydeGGJw34jfvpx8d0pCErOYmXOYdx/MD2MV8n\nEgTr10M33btPJGkSGVReBcw1s7coeoOcfkmrSjJe9PTRaCfyfwynDzvyLQ9yKQMZxCq2iPkatWpt\nDBERSb5EAmECWnMgCYq+P0G0bfmBB+jH2TzDPFrTkY+ZwoFxX6dpU1iyJImFikgJiQTCOGC38Osv\n3P3PJNYjGSwyfbQo50Ie5W6upD6/cwO3cSdXs4bNYr5GVhY8/ri6hkTSobStK2oT3BjnIqCQYKRv\nJzN7FBio/YwkWqww2I3/MoqLOYp3eY/D6MVoPudvMa/Py1MIiKRbaYPKdwGNgJ3dfT933xfYFWgI\n3J2K4qRqix40jg6D2qzhWu5gDm3Zl5n0YhRH8m7MMIisJVAYiKRfaV1GJwF7uG9c+uPuv5pZLrAQ\n6J/s4qTqijdovD9TGUNP2jGHZzmTvgzje3YocZ72HRKpekprIXh0GEQdXEd4s5yKMrO7zGyhmc0x\ns+fNrOGmvJ6k1tZblwyD+qziXi5nMgfRhOWcxvN04dkiYdCpU9AacFcYiFRFpQVCgZmdV/ygmXUn\naCFsireANu7eluAezddt4utJksXrHgI4jteYRxsu5z5GcTE5FPAip214PisrGCOYqA1PRKq00rqM\nLgEmmNlFwIzwWHugHnD6prypu78Z9fATdAe2Kq1PHxgxouTxbfiRoVxON56igFYczId8zMFFztFg\nsUjmiBsI7r4EOMDMjiLY8hrgVXePMct8k1xEMLU1JjPrBfQCaN5cm6ymWn5+rDBwzuMJ7mUAW/Ab\nN3Ezg7mWv9i8yFkKA5HMYjGGCSrnhc0mQsy9CAa6+4vhOQMJWh1nxBqvKK59+/Y+ffr0yi1U4oq1\nyGwXvmQkvTmaiXxER3oyhgXkFDmnbl0YO1ZhIFJVmNkMd29f1nmJLEyrEHfvXNrz4VbaJwGdEgkD\nSZ1YXURZrGUA93IzN7OW2uQynFFcjIfDUGbw5JMKAZFMlrRAKI2ZHQdcDRzu7qvTUYPEFrmXcbR9\nmMlYerAvn/ICp3IJD7GUZhue13bUItVDIjfISYYHgS2At8xslpmNTFMdEopsTx0dBtn8zl1cyTT2\nZwe+40ye5XSeLxIGnTopDESqi7S0ENx9t7LPklSIN4PoaN5kJL3Zha8ZRS+uYQi/sHG5iBaWiVQ/\naQkEqRpidQ81Zjn3MoDzeJLP2IPDeI8PNtwsL6AwEKme0tVlJGkUq3sInG7ksYBWdOU/3MYNtGN2\niTDIzVUYiFRXaiHUIPG6h1ryNSPI5TjeYDIH0pMxzKdNkXM0lVSk+lMLoZrLz4cGDYJpobGmkl7O\nvcyjDQfzEZcyjEP4sEgY1K4EM9ttAAAO8UlEQVQdLDD74w+FgUh1pxZCNRbv7mUA7ZjFWHrQnhm8\nzEn0YTjfslORczp10v5DIjWJWgjVUH4+bL557DCox2oGcw3Tac9OfMPfGccpvFQkDBo00GZ0IjWR\nWgjVRH4+9O8PK1bEP+co3mYUF7MbX/IwF3EVd/EzjTY8r9lDIjWbWgjVQJ8+0L17/DBoxAoe4ULe\npjOOcSTv0IOHi4RBp04KA5GaToGQwSIDxrFmDgWcs3maBbSiO3ncznW0ZQ6TOHLDGeoeEpEIdRll\nqHhTSCN2YjEjyOVEXmUq+9OZicylLRCEwMiRmjUkIkUpEDJQaWFQi3VcyoMMYiAAlzGUYfRlPVma\nNSQipVKXUQYpq4uoDXP5mI7cz2W8z2G0Zj73cxmb1c1St5CIlEmBkCEiA8e//17yuc35k38zkJns\ny858TVee4kRe4dtaLcjN1aIyEUmMAqEKy8+Hli1jrzKOOJxJzKEtA7mdfLrRigVsndsVd2PdOhg+\nPKUli0gGUyBUMdEh0L07FBbGPq8hPzOGHkziSLJYR2feom+Dx3ggr7FCQEQqRIFQhfTpA+eeGz8E\nAs5ZjGcBrbiAx7iTq9iLueyR25nfflPXkIhUnGYZVQGJrDIG2JFveIhLOIWXmcG+HM9rzGIfcnPV\nNSQim04thDSI7haqVav0VcYAxnr68BAF5NCZiVzB3RzAFL5osA95eQoDEakcaiGkUKyWgHvp1+Qw\nnzH0pCOTeYNj6M1ICm1nevdWEIhI5VILIUXy86FXr7K7hSI243/cwo18yj7swed050mO43W8xc48\n+aTCQEQqnwIhCSJdQrVqQZMmwZ/u3WH16sSuP4QPmE07buQ2xnE2x+y4gOPzuuNuLFqkgWMRSQ51\nGVWySEsg8uGfaIsAYEt+YQjX0JtRFNZqyTtXvs65Q47l3OSUKiJShAKhkg0cmHhLINrpTOBBLmU7\nfmDB8QNoNf5WWtSvX/kFiojEoS6jShDdRVT6GoKSmtlSnuMMJnAmdVtsR9a0KbR69R5QGIhIiikQ\nNlGki6iwsOwZQ9FaNl/PlAtH8u0WrTij7mswZAiN/jsV2rdPXrEiIqVQIJRTdGugZctgGml5uoiy\ns+GlIQv4uvnhdHg0NwiAuXPh6quhTp1klS0iUiYFQgzFP/Tz8zcej24NFBaWsaDMoHHj4I8Z7N78\nf0w+7hZO/tfewf0qH3002JN6t91S8W2JiJRKg8rFFJ8lVFgYPIbyDRi3aAGLFkUd+Phj6NkTJhRA\n165w332w7baVWbqIyCZRC6GYWB/6q1cHxxcvTuw1srNh0KDwwa+/wiWXwCGHwKpV8Mor8NRTCgMR\nqXIUCMXE+9BfvBiaN4/9XOPGQYvALPh79Ohw8diLL0JOTnAzg379gm6iE05IWu0iIptCgVBMvA/9\n5s2D3/qzs4sez86G++8PuofWrw/+7nbUd9ClC5x2GjRqBJMnB11EDRoku3wRkQpTIBQT70N/0KDg\nt/7Ro+O0BiBIhDFjoFUrePnl4KIZM+CAA1L+fYiIlJcGlYuJfLhHxgwiLYPI8W7d4uwl9Nlnwejz\n++/DEUfAqFGwxx6pKltEZJOltYVgZleYmZtZk3TWUVy3bsW6gErbTO6vv4LEaNcO5syBsWPhnXcU\nBiKScdLWQjCznYBjgATn7lRBU6ZAjx4wb14wZvDAA7D99umuSkSkQtLZQhgKXA2UY8OHKuK334JZ\nQwcdBCtXwksvwTPPKAxEJKOlJRDM7FRgibvPTuDcXmY23cymL1u2LAXVleGVV6B1a3jwwWB9wfz5\ncPLJ6a5KRGSTJa3LyMwmArF+ZR4IXE/QXVQmdx8NjAZo3759+loTP/wQbFw0blwQCB99FLQQRESq\niaQFgrt3jnXczPYCdgZmmxnAjsBMM+vg7t8nq54Kcw/2HLrySvj9d7j1VrjmGthss3RXJiJSqVI+\nqOzuc4EN+zaY2SKgvbsvT3UtZfriC7j44mDW0KGHBosO9twz3VWJiCSFFqbFsmYNDB4Me+0F06fD\nyJEwaZLCQESqtbQvTHP3lumuoYhp04JdSWfPhjPOgGHDoGnTdFclIpJ0aiFErFoFAwbAgQfCsmXw\n/PPw3HMKAxGpMdLeQqgSXn8devcObn6Qmwt33AFbbZXuqkREUqpmtxCWLQv2pTj+eKhXDz74AIYP\nVxiISI1UMwPBHZ54ItiVdPx4uOkmmDUruImNiEgNVfO6jL76Kugeeust6NgxmEraunW6qxIRSbua\n00JYuxbuvhvatIFPPoGHHgq6iBQGIiJATWkhzJwZTCWdORNOPTXYh2jHHdNdlYhIlVIzAmHsWFi6\nFJ59NlhbEGyZISIiUap9l1F+PrT5v8E0+r6AllecSf5TCgMRkViqdQshPz+4q+Xq1VsC8HNh8BjK\nuAuaiEgNVK1bCAMHwurVRY+tXh0cFxGRoqp1ICyOc3POeMdFRGqyah0IzZuX77iISE1WrQNh0CDI\nzi56LDs7OC4iIkVV60Do1i1YiNyiRTDTtEWL4LEGlEVESqrWs4wg+PBXAIiIlK1atxBERCRxCgQR\nEQEUCCIiElIgiIgIoEAQEZGQuXu6a0iYmS0DCpP8Nk2A5Ul+j2TJ5Nohs+vP5NpB9adTKmpv4e7b\nlHVSRgVCKpjZdHdvn+46KiKTa4fMrj+TawfVn05VqXZ1GYmICKBAEBGRkAKhpNHpLmATZHLtkNn1\nZ3LtoPrTqcrUrjEEEREB1EIQEZGQAkFERAAFQglmdpuZzTGzWWb2ppk1TXdN5WFmd5nZwvB7eN7M\nGqa7pkSZWRczm29m682sSkzDS4SZHWdmn5nZF2Z2bbrrKQ8ze8TMfjSzeemupbzMbCcze9fMCsJ/\nN/3TXVN5mFldM5tqZrPD+m9Je00aQyjKzLZ091/Dr/sBOe7eO81lJczMjgHecfe1ZjYEwN2vSXNZ\nCTGzVsB6YBRwpbtPT3NJZTKzLOBz4GjgW2Aa0NXdC9JaWILM7DBgFfCEu7dJdz3lYWY7ADu4+0wz\n2wKYAZyWQT97A+q7+yozqwN8CPR390/SVZNaCMVEwiBUH8ioxHT3N919bfjwE2DHdNZTHu6+wN0/\nS3cd5dQB+MLdv3L3v4CngVPTXFPC3P194Kd011ER7v6du88Mv/4NWAA0S29VifPAqvBhnfBPWj9v\nFAgxmNkgM/sG6AbcmO56NsFFwGvpLqKaawZ8E/X4WzLoQ6m6MLOWwD7AlPRWUj5mlmVms4Afgbfc\nPa3118hAMLOJZjYvxp9TAdx9oLvvBOQDl6a32pLKqj88ZyCwluB7qDISqV2kPMysAfAccFmxFn6V\n5+7r3H1vgpZ8BzNLa7ddtb+FZizu3jnBU/OBV4GbklhOuZVVv5ldAJwEdPIqNkhUjp99plgC7BT1\neMfwmKRA2Pf+HJDv7hPSXU9FuftKM3sXOA5I2wB/jWwhlMbMdo96eCqwMF21VISZHQdcDZzi7qvT\nXU8NMA3Y3cx2NrPNgHOAl9JcU40QDso+DCxw93vTXU95mdk2kVmAZlaPYGJCWj9vNMuoGDN7Dvgb\nwWyXQqC3u2fMb3xm9gWwObAiPPRJpsySMrPTgWHANsBKYJa7H5veqspmZicA9wFZwCPuPijNJSXM\nzP4DHEGwBfMPwE3u/nBai0qQmR0CfADMJfj/FeB6d381fVUlzszaAo8T/LupBTzj7remtSYFgoiI\ngLqMREQkpEAQERFAgSAiIiEFgoiIAAoEEREJKRAkLcyscbij7Cwz+97MloRfrzSzlG5OZmZ7h1NH\nI49PqeiupWa2yMyaVF515XrvC6J35zWzsWaWk+66JHMoECQt3H2Fu+8dLtsfCQwNv96bjXPKK42Z\nlbYqf29gQyC4+0vuPriya0iBC4ANgeDuPTJl50+pGhQIUhVlmdmYcI/4N8NVnJjZrmb2upnNMLMP\nzGzP8HhLM3snvAfE22bWPDz+mJmNNLMpwJ1mVj/c/3+qmX1qZqeGq4tvBc4OWyhnh79pPxi+xnYW\n3FdidvinY3j8hbCO+WbWq6xvyMwuNLPPw/ceE/X6j5nZWVHnrQr/bhB+LzPNbG5kr6fwe11Q/OcT\nvkZ7ID/8PuqZ2SSLcV8JM+se1jHLzEZZsMFaVljLvPD9Lt+E/36SoRQIUhXtDjzk7q0JViyfGR4f\nDfR19/2AK4Hh4fFhwOPu3pZg/6kHol5rR6Cjuw8ABhLcK6IDcCRwF8GWwzcC48IWy7hitTwAvOfu\n7YB9gfnh8YvCOtoD/cyscbxvxoJ9+28BDgYOAXIS+Bn8CZzu7vuGtd4TbtUQ8+fj7s8C04Fu4ffx\nR5xaWgFnAweHLbJ1BLv67g00c/c27r4X8GgCNUo1UyM3t5Mq72t3nxV+PQNoGe5o2REYv/Fzkc3D\nvw8Czgi/fhK4M+q1xrv7uvDrY4BTzOzK8HFdoHkZtRwFnAfBzpTAL+HxfuFWGxBsbrc7G7cLKe4A\nYJK7LwMws3HAHmW8rwG3W3ADm/UEW2pvFz5X4udTxmtF6wTsB0wLf471CLZefhnYxcyGAa8Ab5bj\nNaWaUCBIVfS/qK/XEXxo1QJWhr/VlsfvUV8bwW/TRW7CY2YHlOcFzewIoDNwkLuvNrNJBOFSEWsJ\nW+pmVgvYLDzejWBPp/3cfY2ZLYp6j1g/n4TLJ2hNXVfiCbN2wLFAb+DvBPfTkBpEXUaSEcJ97r82\nsy4Q7HQZfoABfEywyygEH6QfxHmZN4C+ka4XM9snPP4bsEWca94GcsPzs8xsK2Ar4OcwDPYEDiyj\n/CnA4eHMqjpAl6jnFhH8xg5wCkEXFuF7/BiGwZFAizLeo6zvI/r7OcvMtg2/p0Zm1iKcgVTL3Z8D\nbiDoHpMaRoEgmaQb8E8zm03Qlx+5qU5f4EIzmwOcC8S72fptBB+4c8xsfvgY4F0gJzKoXOya/sCR\nZjaXoHsmB3gdqG1mC4DBBLcqjcvdvwNuBiYDHxHc6jFiDEFYzCbo+oq0aPKB9uH7nkdi2yI/BoyM\nDCrHqaWA4AP/zfDn9RawA0GX1CQL7t6VB5RoQUj1p91ORVLMghsYtXf3Knc3PqnZ1EIQERFALQQR\nEQmphSAiIoACQUREQgoEEREBFAgiIhJSIIiICAD/DzWvEKJN9NYmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs8flRZ9QY4U",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td-HGSkXQzvf",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scaling and Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe3mkIwCQ2nd",
        "colab_type": "text"
      },
      "source": [
        "### Min-Max Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmRBQbrFRCJe",
        "colab_type": "text"
      },
      "source": [
        "Min-max scaling squeezes (or stretches) all feature values to be within the range of [0,1].\n",
        "\n",
        "$\\hat{x} = \\frac{x - min(x)}{max(x) - min(x)}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49JlHBQdUXUD",
        "colab_type": "text"
      },
      "source": [
        "### Standardization (Variance Scaling)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsbWhB3DUiQ9",
        "colab_type": "text"
      },
      "source": [
        "$\\hat{x} = \\frac{x-mean(x)}{\\sqrt{var(x)}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voqI8VW0U9Z_",
        "colab_type": "text"
      },
      "source": [
        "!!!DON'T \"CENTER\" SPARSE DATA!!!\n",
        "\n",
        "Bag-of-words is a sparse representation, and most classification libraries optimize for sparse inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmobsJjbVI8k",
        "colab_type": "text"
      },
      "source": [
        "### $l^2$ Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3LPTDM3VoYp",
        "colab_type": "text"
      },
      "source": [
        "It normalizes (divides) the original feature value by the euclidean norm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwUKpnhzVzDH",
        "colab_type": "text"
      },
      "source": [
        "$\\hat{x} = \\frac{x}{||x||_2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui4Xo1Y5V_03",
        "colab_type": "text"
      },
      "source": [
        "Scaling does not change the shape of the single-feature distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_0XaOZnWf8c",
        "colab_type": "text"
      },
      "source": [
        "Feature scaling is useful in situations where a set of input features differs wildly in scale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zPfhpDmW9EQ",
        "colab_type": "text"
      },
      "source": [
        "## Interaction Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUaIDBhNW_5U",
        "colab_type": "text"
      },
      "source": [
        "- A simple pairwise interaction feature is the product of two features.\n",
        "- Decision tree-based model getthis for free, but generalized linear models often find interaction features very helpful.\n",
        "- This allows us to capture interactions between features, and hence these pairs called interaction features.\n",
        "- If x and x are binary, then their product x1x2 is the\n",
        "logical function x1 AND x2.\n",
        "- Very simple to formulate, but they very expensive to use.\n",
        "- Ways for the expensive computation:\n",
        "    - Perform feature selection on top of all of the interaction features. Selecting the best features for a problem.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VBqWiPRZd23",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7RJlYzebIbb",
        "colab_type": "text"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_gOBmUTbRPK",
        "colab_type": "text"
      },
      "source": [
        "- Prune away nonuseful features in order to reduce the complexity of the resulting model.\n",
        "- In\n",
        "order to arrive at such a model, some feature selection techniques require\n",
        "training more than one candidate model.\n",
        "\n",
        "Roughly speaking, feature selection falls into three classes:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-cHsj0rbxwM",
        "colab_type": "text"
      },
      "source": [
        "Filter\n",
        "\n",
        "Filtering techniques preprocess features to remove ones that are unlikely to\n",
        "be useful for the model. For example, one could compute the correlation or\n",
        "mutual information between each feature and the response variable, and filter\n",
        "out the features that fall below a threshold. It is best to do prefiltering conservatively, so as not to\n",
        "inadvertently eliminate useful features before they even make it to the model\n",
        "training step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCZVyzQ0cXya",
        "colab_type": "text"
      },
      "source": [
        "Wrapper methods\n",
        "\n",
        "These techniques are expensive, but they allow you to try out subsets of\n",
        "features, which means you wonâ€™t accidentally prune away features that are\n",
        "uninformative by themselves but useful when taken in combination. The\n",
        "wrapper method treats the model as a black box that provides a quality score\n",
        "of a proposed subset for features. There is a separate method that iteratively\n",
        "refines the subset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6u6Ks-AccUA",
        "colab_type": "text"
      },
      "source": [
        "Embedded methods\n",
        "\n",
        "These methods perform feature selection as part of the model training\n",
        "process. For example, a decision tree inherently performs feature selection\n",
        "because it selects one feature on which to split the tree at each training step. Another example is l1 regularization. Compared to filtering,\n",
        "embedded methods select features that are specific to the model. In this\n",
        "sense, embedded methods strike a balance between computational expense\n",
        "and quality of results."
      ]
    }
  ]
}